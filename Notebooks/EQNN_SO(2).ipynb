{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270ad030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer, GradientDescentOptimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a34109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_layer(X):\n",
    "    for i in range(X.shape[0]):\n",
    "        qml.RZ(-1*X[i,2],wires=i)\n",
    "        qml.RY(X[i,0],wires=i)\n",
    "        qml.RX(X[i,1],wires=i)\n",
    "        qml.RZ(X[i,2],wires=i)\n",
    "        \n",
    "def rbs(theta, wires):\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    U = np.array([[1, 0, 0, 0], [0, a, b, 0], [0, -b, a, 0], [0, 0, 0, 1]], requires_grad=True)\n",
    "    qml.QubitUnitary(U, wires=wires)\n",
    "        \n",
    "def XY_layer(N,params):\n",
    "    for i in range(N-1):\n",
    "#         qml.IsingXY(params[i],wires = [i,i+1])\n",
    "#     qml.IsingXY(params[N-1],wires = [N-1,0])\n",
    "        rbs(params[i],wires = [i,i+1])\n",
    "    rbs(params[N-1],wires = [N-1,0])\n",
    "    \n",
    "def Y_pooling(N):\n",
    "    n2 = N//2\n",
    "    for i in range(n2):\n",
    "        qml.CY(wires=[i+n2, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c0dbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=10)\n",
    "\n",
    "def process_data2(Data):\n",
    "    Data[:,:,0]*=(1/250)\n",
    "    Index = Data[:,:,2]-2*np.pi>0\n",
    "    Data[Index,2]-= 2*np.pi\n",
    "    Index2 = Data[:,:,2]<0\n",
    "    Data[Index2,2]+= 2*np.pi\n",
    "    Data[:,:,2]-=np.pi\n",
    "    return np.array(Data[:,:,:3])\n",
    "\n",
    "\n",
    "Path =  '../data/'\n",
    "Data = np.load(Path+'Sorted_10_data.npy')\n",
    "Label = np.load(Path+'Sorted_10_label.npy')\n",
    "Data = process_data2(Data)\n",
    "Label = np.array(Label).astype(int)\n",
    "\n",
    "Data = np.array(Data, requires_grad=False)\n",
    "Label = np.array(Label, requires_grad=False)\n",
    "\n",
    "idx = np.arange(Data.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "Data,Label = Data[idx], Label[idx]\n",
    "\n",
    "Train_data, Train_label = Data[:700,:10,:], Label[:700]\n",
    "Test_data, Test_label = Data[700:800,:10,:], Label[700:800]\n",
    "\n",
    "Train_data, Train_label = np.array(Train_data, requires_grad=False),np.array(Train_label, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b1a8182",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0 = [[np.sqrt(2), 0, 0, 0],\n",
    "        [0, 1, 1, 0],\n",
    "        [0, 1, -1, 0],\n",
    "        [0, 0, 0, np.sqrt(2)]]\n",
    "label_1 = [[np.sqrt(2), 0, 0, 0],\n",
    "        [0, -1, 1, 0],\n",
    "        [0, 1, 1, 0],\n",
    "        [0, 0, 0, np.sqrt(2)]]\n",
    "state_labels = np.array([label_0, label_1], requires_grad=False)\n",
    "def density_matrix(state):\n",
    "#     return state * np.conj(state).T\n",
    "    return state/np.sqrt(2)\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qcircuit(params, x, y):\n",
    "    \n",
    "\n",
    "    \n",
    "    embedding_layer(x)\n",
    "#     XY_layer(10,params)\n",
    "    XY_layer(10,params[:10])\n",
    "    embedding_layer(x)\n",
    "    XY_layer(10,params[10:20])\n",
    "    embedding_layer(x)\n",
    "    XY_layer(10,params[20:30])\n",
    "\n",
    "    Y_pooling(10)\n",
    "    \n",
    "    XY_layer(5,params[30:35])\n",
    "    Y_pooling(5)\n",
    "    \n",
    "    Y_pooling(4)\n",
    "    \n",
    "    qml.CY(wires=[4, 0])\n",
    "\n",
    "    \n",
    "    return qml.expval(qml.Hermitian(y, wires=[0,1]))\n",
    "\n",
    "def cost(params, x, y, state_labels=None):\n",
    "    # Compute prediction for each input in data batch\n",
    "    loss = 0.0\n",
    "    dm_labels = [density_matrix(s) for s in state_labels]\n",
    "    for i in range(len(x)):\n",
    "        ypred = qcircuit(params, x[i], dm_labels[0])\n",
    "        loss = loss  -y[i] * np.log(ypred, requires_grad=True) - (1 - y[i]) * np.log(1 - ypred, requires_grad=True)\n",
    "    return loss / len(x)\n",
    "\n",
    "def test(params, x, y, state_labels=None):\n",
    "    fidelity_values = []\n",
    "    dm_labels = [density_matrix(s) for s in state_labels]\n",
    "    predicted = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "#         fidel_function = lambda y: qcircuit(params, x[i], y)\n",
    "        fidelities = qcircuit(params, x[i], dm_labels[0])\n",
    "        best_fidel = np.rint(fidelities)\n",
    "\n",
    "        predicted.append(best_fidel)\n",
    "        fidelity_values.append(fidelities)\n",
    "\n",
    "    return np.array(predicted), np.array(fidelity_values)\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    score = y_true == y_pred\n",
    "    return score.sum() / len(y_true)\n",
    "\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batch_size):\n",
    "    for start_idx in range(0, inputs.shape[0] - batch_size + 1, batch_size):\n",
    "        idxs = slice(start_idx, start_idx + batch_size)\n",
    "        yield inputs[idxs], targets[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e690deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 | Loss: 0.716095 | Train accuracy: 0.518571 | Test accuracy: 0.530000\n",
      "Epoch:  2 | Loss: 0.710201 | Train accuracy: 0.527143 | Test accuracy: 0.570000\n",
      "Epoch:  3 | Loss: 0.706640 | Train accuracy: 0.522857 | Test accuracy: 0.600000\n",
      "Epoch:  4 | Loss: 0.704093 | Train accuracy: 0.524286 | Test accuracy: 0.630000\n",
      "Epoch:  5 | Loss: 0.702161 | Train accuracy: 0.527143 | Test accuracy: 0.630000\n",
      "Epoch:  6 | Loss: 0.700630 | Train accuracy: 0.527143 | Test accuracy: 0.640000\n",
      "Epoch:  7 | Loss: 0.699375 | Train accuracy: 0.527143 | Test accuracy: 0.650000\n",
      "Epoch:  8 | Loss: 0.698317 | Train accuracy: 0.534286 | Test accuracy: 0.640000\n",
      "Epoch:  9 | Loss: 0.697402 | Train accuracy: 0.540000 | Test accuracy: 0.610000\n",
      "Epoch: 10 | Loss: 0.696592 | Train accuracy: 0.538571 | Test accuracy: 0.600000\n",
      "Epoch: 11 | Loss: 0.695859 | Train accuracy: 0.537143 | Test accuracy: 0.600000\n",
      "Epoch: 12 | Loss: 0.695186 | Train accuracy: 0.542857 | Test accuracy: 0.590000\n",
      "Epoch: 13 | Loss: 0.694558 | Train accuracy: 0.541429 | Test accuracy: 0.580000\n",
      "Epoch: 14 | Loss: 0.693967 | Train accuracy: 0.540000 | Test accuracy: 0.570000\n",
      "Epoch: 15 | Loss: 0.693406 | Train accuracy: 0.535714 | Test accuracy: 0.580000\n",
      "Epoch: 16 | Loss: 0.692870 | Train accuracy: 0.540000 | Test accuracy: 0.590000\n",
      "Epoch: 17 | Loss: 0.692356 | Train accuracy: 0.544286 | Test accuracy: 0.590000\n",
      "Epoch: 18 | Loss: 0.691862 | Train accuracy: 0.545714 | Test accuracy: 0.600000\n",
      "Epoch: 19 | Loss: 0.691387 | Train accuracy: 0.547143 | Test accuracy: 0.590000\n",
      "Epoch: 20 | Loss: 0.690930 | Train accuracy: 0.545714 | Test accuracy: 0.590000\n",
      "Epoch: 21 | Loss: 0.690490 | Train accuracy: 0.554286 | Test accuracy: 0.560000\n",
      "Epoch: 22 | Loss: 0.690067 | Train accuracy: 0.557143 | Test accuracy: 0.550000\n",
      "Epoch: 23 | Loss: 0.689660 | Train accuracy: 0.557143 | Test accuracy: 0.510000\n",
      "Epoch: 24 | Loss: 0.689271 | Train accuracy: 0.562857 | Test accuracy: 0.500000\n",
      "Epoch: 25 | Loss: 0.688897 | Train accuracy: 0.561429 | Test accuracy: 0.480000\n",
      "Epoch: 26 | Loss: 0.688541 | Train accuracy: 0.564286 | Test accuracy: 0.480000\n",
      "Epoch: 27 | Loss: 0.688200 | Train accuracy: 0.564286 | Test accuracy: 0.480000\n",
      "Epoch: 28 | Loss: 0.687875 | Train accuracy: 0.567143 | Test accuracy: 0.480000\n",
      "Epoch: 29 | Loss: 0.687566 | Train accuracy: 0.570000 | Test accuracy: 0.490000\n",
      "Epoch: 30 | Loss: 0.687273 | Train accuracy: 0.574286 | Test accuracy: 0.480000\n",
      "Epoch: 31 | Loss: 0.686994 | Train accuracy: 0.571429 | Test accuracy: 0.470000\n",
      "Epoch: 32 | Loss: 0.686730 | Train accuracy: 0.570000 | Test accuracy: 0.480000\n",
      "Epoch: 33 | Loss: 0.686480 | Train accuracy: 0.571429 | Test accuracy: 0.480000\n",
      "Epoch: 34 | Loss: 0.686243 | Train accuracy: 0.572857 | Test accuracy: 0.460000\n",
      "Epoch: 35 | Loss: 0.686019 | Train accuracy: 0.571429 | Test accuracy: 0.460000\n",
      "Epoch: 36 | Loss: 0.685806 | Train accuracy: 0.574286 | Test accuracy: 0.460000\n",
      "Epoch: 37 | Loss: 0.685605 | Train accuracy: 0.578571 | Test accuracy: 0.460000\n",
      "Epoch: 38 | Loss: 0.685414 | Train accuracy: 0.581429 | Test accuracy: 0.460000\n",
      "Epoch: 39 | Loss: 0.685233 | Train accuracy: 0.587143 | Test accuracy: 0.460000\n",
      "Epoch: 40 | Loss: 0.685061 | Train accuracy: 0.585714 | Test accuracy: 0.460000\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-3\n",
    "epochs = 40\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "\n",
    "# # initialize random weights\n",
    "params = np.random.uniform(size=35, requires_grad=True)\n",
    "# best_params = np.load('best_params_task_VII.npy')\n",
    "# params = best_params\n",
    "\n",
    "opt = AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999)\n",
    "\n",
    "best_val_accuracy = 0\n",
    "\n",
    "for it in range(epochs):\n",
    "#     print(params[:10])\n",
    "    for Xbatch, ybatch in iterate_minibatches(Train_data, Train_label, batch_size=batch_size):\n",
    "        params, _, _, _ = opt.step(cost, params, Xbatch, ybatch, state_labels)\n",
    "    \n",
    "    predicted_train, fidel_train = test(params, Train_data, Train_label, state_labels)\n",
    "    accuracy_train = accuracy_score(Train_label, predicted_train)\n",
    "    loss = cost(params, Train_data, Train_label, state_labels)\n",
    "    \n",
    "    predicted_test, fidel_test = test(params, Test_data, Test_label, state_labels)\n",
    "    accuracy_test = accuracy_score(Test_label, predicted_test)\n",
    "    \n",
    "    if accuracy_test > best_val_accuracy:\n",
    "        best_params = params.copy()\n",
    "        best_val_accuracy = accuracy_test\n",
    "    res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "    print(\n",
    "        \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(\n",
    "            *res\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b4a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
